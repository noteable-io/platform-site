---
slug: chat-with-data-driven-documents
title: Chat with Data Driven Documents
authors: [kyle]
tags: [chatgpt, ipython, notebooks, noteable]
---

```python cell count=1
import openai
import noteable
```

There's a bit of a debate about OpenAI's Code Interpreter vs. Noteable Notebooks. That's silly. They're both using GPT models! The difference is in the interface and the environment provided. OpenAI is providing several incredible bits we've been building on top of:

- ChatGPT Plugins
- Chat Completions API
- Function Calling

OpenAI has built an incredible suite of large language models. Each release is better than the last.

I remember first trying out the earlier GPT-3 models and was blown away. I wasn't sure if the cost was worth it

## Noteable, ChatGPT, and the Code Interpreter

# Outline

- Delight about how these large language models can reason about coding and analysis tasks
- Initial experiments with OpenAI's models, with `genai` and exception handling
- Plugin: from `dangermode` to `noteable`
- Scaling up, a la tmpnb
- Futures

## Strengths

- The result of computation with the model is stored in a data driven document, a notebook
- We believe in the power of notebooks as expressive reproducible communication tools
- Flexible hosted environment that gives you access to what you need

the result of computation with the model is stored in a data driven document, a notebook
We believe in the power of notebooks as expressive reproducible communication tools
and hosted environment gives you access to what you need
In both code interpreter and Noteable it helps you see the raw power in OpenAI's Large Language Models. I can't wait to see these models improve for all computational workflows. There is a lot to explore, automate, and discover.
There are a few areas where the Noteable plugin is much weaker:

speed of startup -- we require starting up a session with a notebook and then creating cells. This is not as fast as "just write code immediately", but it gives you persistence
We do not control the model, temperature, etc.
These last two are much better handled with direct usage of our realtime service using chat functions, where there's a lot more control and even speed, context, and customization.
